> タイトル<br>
Visual Transformer Network for Object Goal Navigation  
オブジェクトゴールナビゲーションのためのVisual Transformer Network
<br>

記入欄
***

> 論文リンク<br>
https://openreview.net/forum?id=DILxQP08O3B
<br>

記入欄
***

> 要約メモ<br>
オブジェクトゴールナビゲーションは、エージェントの観察結果に基づいて、エージェントをターゲットオブジェクトに向けて誘導することを目的としています。ナビゲーションの行動を決定するためには、観察されたシーンの効果的な視覚表現を設計することが極めて重要である。 本論文では、ナビゲーションにおける有益な視覚表現を学習するために、Visual Transformer Network (VTNet)を紹介します。 VTNetは、視覚表現のための2つの重要な特性を具現化する非常に効果的な構造です。VTNetは、シーン内の全てのオブジェクトインスタンス間の関係を利用し、第二に、オブジェクトや画像領域の空間的な位置を強調することで、方向性のあるナビゲーション信号を学習することができます。さらに、視覚表現とナビゲーション信号を関連付けるための事前学習スキームを開発し、ナビゲーションポリシーの学習を促進しています。VTNetは、オブジェクトとリージョンの特徴を、それらの位置情報を持つ空間認識記述子として埋め込み、注意操作によってエンコードされた記述子をすべて組み込み、ナビゲーションのための有益な表現を実現します。このような視覚表現があれば、エージェントは、視覚的観察とナビゲーション・アクションの間の相関関係を探ることができます。例えば、エージェントは、視覚表現が活性化マップの右側を強調している場合、「右に曲がる」ことを「左に曲がる」ことよりも優先させることができる。人工的な環境であるAI2-Thorを用いた実験により、VTNetは目に見えないテスト環境において最先端の手法を大幅に上回ることが実証されました。
<br>

記入欄
***

> どんなもの？<br>

<br>

記入欄
***

> 先行文献と比べてどこがすごい？

<br>

記入欄
***

> 技術や手法のキモは？

<br>

記入欄
***

> どうやって有効性を証明した？

<br>

記入欄
***

> 議論はある？

<br>

記入欄
***

> 分からない単語、調べた内容メモ

<br>

記入欄
***

> 参考リンク

<br>

記入欄
***