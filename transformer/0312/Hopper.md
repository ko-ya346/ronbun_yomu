> タイトル<br>
Hopper: Multi-hop Transformer for Spatiotemporal Reasoning   
Hopper: 時空間推論のためのマルチホップ・トランスフォーマー（Multi-hop Transformer for Spatiotemporal Reasoning 
<br>

記入欄
***

> 論文リンク<br>
https://openreview.net/forum?id=MaZFq7bJif7
<br>

記入欄
***

> 要約メモ<br>
本論文では、動画における時空間的なオブジェクト中心の推論の問題を考察する。我々のアプローチの中心となるのは、オブジェクトパーマネンスの概念であり、つまり、他のオブジェクトに遮られたり、含まれたり、運ばれたりしながらビデオ内を移動するオブジェクトの位置を推論する能力である。既存の深層学習ベースのアプローチは、ビデオ推論問題に適用すると時空間バイアスに悩まされることが多い。本研究では、マルチホップトランスフォーマーを用いて、映像中の物体の永続性を推論するHopperを提案する。Hopperは、動画と位置特定のためのクエリが与えられると、画像とオブジェクトのトラックを推論し、反復的な方法で重要なフレームを自動的にホップして、対象のオブジェクトの最終的な位置を予測します。また，時空間的なバイアスを低減するためにコントラスト損失を用いることの有効性を示した．CATERデータセットを用いて評価したところ、Hopperはわずか数枚のクリティカルフレームをホップすることで、わずか1FPSで73.2%のトップ1精度を達成した。また、CATER-hデータセットを構築し、興味のある物体を正しく配置するために多段階の推論を必要とすることで、Hopperが長期的な推論を行うことができることを示した。
<br>

記入欄
***

> どんなもの？<br>

<br>

記入欄
***

> 先行文献と比べてどこがすごい？

<br>

記入欄
***

> 技術や手法のキモは？

<br>

記入欄
***

> どうやって有効性を証明した？

<br>

記入欄
***

> 議論はある？

<br>

記入欄
***

> 分からない単語、調べた内容メモ

<br>

記入欄
***

> 参考リンク

<br>

記入欄
***