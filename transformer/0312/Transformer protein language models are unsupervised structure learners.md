> タイトル<br>
Transformer protein language models are unsupervised structure learners
<br>

記入欄
***

> 論文リンク<br>
https://openreview.net/forum?id=fylclEqgvgd
<br>

記入欄
***

> 要約メモ<br>
タンパク質の構造決定や設計において、物理的、構造的、機能的な制約を明らかにするためには、教師なしの接触予測が中心となる。数十年にわたり、主なアプローチは、関連する配列のセットから進化的制約を推論することでした。しかし、バイオインフォマティクスの分野では、タンパク質の言語モデルが登場しているが、その性能は最先端のアプローチに及ばない。本論文では、Transformerのアテンションマップが、教師なしの言語モデリングの目的から接点を学習することを実証した。現在までに学習された最高容量のモデルは、最先端の教師なし接触予測パイプラインをすでに凌駕していることがわかった。このことは、これらのパイプラインが、エンドツーエンドモデルの1回のフォワードパスで置き換えられることを示唆している。
<br>

記入欄
***

> どんなもの？<br>

<br>

記入欄
***

> 先行文献と比べてどこがすごい？

<br>

記入欄
***

> 技術や手法のキモは？

<br>

記入欄
***

> どうやって有効性を証明した？

<br>

記入欄
***

> 議論はある？

<br>

記入欄
***

> 分からない単語、調べた内容メモ

<br>

記入欄
***

> 参考リンク

<br>

記入欄
***