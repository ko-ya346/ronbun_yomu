> タイトル<br>
DeLighT: Deep and Light-weight Transformer
<br>

記入欄
***

> 論文リンク<br>
https://openreview.net/forum?id=ujmgfuxSLrO
<br>

記入欄
***

> 要約メモ<br>
DeLighTは、標準的なトランスフォーマーベースのモデルと同等以上の性能を、大幅に少ないパラメータで実現する深層軽量トランスフォーマーである。DeLighTは、(1)軽量で深い変換であるDeLighT変換を用いて各Transformerブロック内で、(2)ブロック単位のスケーリングを用いてブロック間で、より効率的にパラメータを割り当てている。全体として、DeLighTネットワークは標準的な変換モデルの2.5倍から4倍の深さがあり、しかもパラメータや演算が少ない。機械翻訳や言語モデリングのベンチマークタスクを用いた実験では、DeLighTは平均して2～3倍少ないパラメータでベースラインのTransformerと同等かそれ以上の性能を発揮した。
<br>

記入欄
***

> どんなもの？<br>

<br>

記入欄
***

> 先行文献と比べてどこがすごい？

<br>

記入欄
***

> 技術や手法のキモは？

<br>

記入欄
***

> どうやって有効性を証明した？

<br>

記入欄
***

> 議論はある？

<br>

記入欄
***

> 分からない単語、調べた内容メモ

<br>

記入欄
***

> 参考リンク

<br>

記入欄
***