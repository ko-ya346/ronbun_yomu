> タイトル<br>
UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers   
トランスフォーマーを用いたポリシーデカップリングによるユニバーサルマルチエージェントRL 
<br>

記入欄
***

> 論文リンク<br>
https://openreview.net/forum?id=v9c7hr9ADKx
<br>

記入欄
***

> 要約メモ<br>
マルチエージェント強化学習の最近の進歩は、新しいタスクごとに1つのモデルをゼロからトレーニングすることに大きく制限されています。この制限は、固定された入力と出力の次元に関連する制限されたモデルアーキテクチャに起因します。これは、様々な難易度のタスク（例えば、3対3や5対6のマルチエージェントゲーム）において、学習したエージェントの経験の蓄積と伝達を妨げる。 本論文では、普遍的なマルチエージェント強化学習パイプラインを探求する最初の試みを行い、1つのアーキテクチャを、異なる観察と行動の構成が要求されるタスクに適合するように設計する。従来のRNNベースのモデルとは異なり、我々は自己注意メカニズムのメリットによって測定された重要性の重みを持つ入力観測と絡み合ったポリシー分布を切り離すことで、柔軟なポリシーを生成するためにトランスフォーマーベースのモデルを利用する。標準的な変換器ブロックと比較して、提案モデルはUniversal Policy Decoupling Transformer (UPDeT)と名付けられ、行動制限をさらに緩和し、マルチエージェントタスクの決定プロセスをより説明しやすくする。UPDeTは、あらゆるマルチエージェント強化学習パイプラインにプラグインできるほど汎用的であり、複数のタスクを同時に処理できる強力な汎用化能力を備えています。大規模なSMACマルチエージェント対戦ゲームでの広範な実験により、提案されたUPDTに基づくマルチエージェント強化学習は、最先端のアプローチと比較して有意な結果を達成し、性能と学習速度（10倍の速度）の両方の点で有利な移行能力を示した。
<br>

記入欄
***

> どんなもの？<br>

<br>

記入欄
***

> 先行文献と比べてどこがすごい？

<br>

記入欄
***

> 技術や手法のキモは？

<br>

記入欄
***

> どうやって有効性を証明した？

<br>

記入欄
***

> 議論はある？

<br>

記入欄
***

> 分からない単語、調べた内容メモ

<br>

記入欄
***

> 参考リンク

<br>

記入欄
***