> タイトル<br>

<br>

Unsupervised Audiovisual Synthesis via Exemplar Autoencoders  
模範的オートエンコーダによる教師なし視聴覚合成
***

> 論文リンク<br>

<br>

https://openreview.net/forum?id=43VKWxg_Sqr
***

> 要約メモ<br>

<br>

記入欄
***

> どんなもの？<br>

<br>

記入欄
***

> 先行文献と比べてどこがすごい？

<br>

記入欄
***

> 技術や手法のキモは？

<br>

記入欄
***

> どうやって有効性を証明した？

<br>

記入欄
***

> 議論はある？

<br>

記入欄
***

> 分からない単語、調べた内容メモ

<br>

記入欄
***

> 参考リンク

<br>

記入欄
***

> 本文直訳

<br>

### abstract
我々は、任意の個人の入力音声を、潜在的に無限に多い出力話者のオーディオビジュアルストリームに変換する教師なしのアプローチを提示する。  
このアプローチは、サンプル外のデータをトレーニングセットの分布に投影する単純なオートエンコーダをベースにしています。  
模範オートエンコーダを用いて，特定のターゲットとなる模範音声の音声，文体の韻律，視覚的な外観を学習する．  
既存の手法とは対照的に，提案手法は，入力話者の訓練データを必要とせず，わずか3分の対象音声・映像データを用いて，任意の数の話者とスタイルに容易に拡張することができる．  
そのために、我々は、音声の構造化された言語的内容を捉える視聴覚ボトルネック表現を学習する。  
本研究では，音声と映像の両方の合成において，先行研究を上回る結果を得ることができた．

### conclusion
本論文では、音声入力から教師なしでオーディオビジュアルを合成するための模範的オートエンコーダを提案する。  
我々のモデルは、実世界のウェブデータや多様な音声入力に一般化することができ、エンターテインメント、教育、支援技術などの分野で新しいアプリケーションを可能にする。  
今回の研究は、オートエンコーダのモデリング能力を再考するきっかけとなりました。  
ある条件の下では、オートエンコーダはある特定の分布に対する射影演算子として機能する。  
付録では、このような技術の潜在的な悪用を含む広範な影響について広範な議論を行っています。  
フォレンジック分類器を使って我々の手法で合成されたコンテンツを検出できるという経験的な証拠を含め、緩和策を検討している。


***

> appendix

<br>

### APPENDIX - BROADER IMPACTS

私たちの研究は、ビデオコンテンツを再ターゲット化するコンテンツ生成に関する一連の研究に沿ったもので、しばしば顔の人形劇の文脈で考えられています。  
エンターテインメントにおける多くのアプリケーションが存在する一方で、深刻な悪用の可能性も多く存在します。  
この分野での過去の研究には、より広範なインパクト・ステートメント（Friedら、2019年、Kimら、2018年）が含まれており、ここではそれを基にしています。  

#### our setup
先行研究と比較して，我々の設定のユニークな点は，
(a)入力および出力モダリティの選択  
(b)学習データの要件  
です。  
(a)に関しては，我々のモデルは音声を入力とし，対象となる個人のパーソナライズされたスタイルとソース入力の言語的内容（単語）を捉えた視聴覚（AV）出力を生成します。このスタイルとコンテンツの因数分解は、私たちの研究の重要な技術的側面です。これまでの研究では、視覚的な画像や映像の生成がもたらす広範な影響について議論されてきましたが、音声編集の責任ある実践についてはあまり議論されていません。以下、この議論を始めます。(b)に関しては、我々のアプローチは、対象となるオーディオとビデオについて数分間のトレーニングを必要とするだけで、大規模な個人集団に対するトレーニングを必要としないという点でユニークです。このことは，一般化可能性と非専門家にとっての使いやすさに影響を与え，実行可能な対象アプリケーションの範囲を広げることになる．私たちがターゲットとするアプリケーションには、娯楽/教育と支援技術があり、それぞれについて以下に説明します。最後に、悪用される可能性があるものと、それを緩和するための戦略について議論する。

#### assistive technology
音声合成の重要なアプリケーションに、会話障害者のための音声生成があります。  
個人のスタイルに合わせて音声を生成することは、アイデンティティを維持する上で非常に重要です。  
私たちは、この分野でのアプリケーションをビデオで紹介しています。  
また、臨床医との共同研究を開始し、発声を直接感知する物理的な装置（電気喉頭など）からのパーソナライズされたスタイルの音声出力を研究しています。  
現在、このような繊細な患者データを取得するには、データとプライバシーに関するかなりの配慮が必要です。私たちは、  
著名人を対象とした結果を示すことで、臨床協力者や潜在的な患者ボランティアとの信頼関係を築くことができると考えています。

#### entertainment/education
高品質のAVコンテンツを制作するには、数分程度のコンテンツを制作するのに数日から数週間かかることもあり、手間のかかる作業です。  
私たちの作品は、歴史上の人物の声によるドキュメンタリーやナレーション（ウィンストン・チャーチル、J・F・ケネディ、ネルソン・マンデラ、マーティン・ルーサー・キング・ジュニアなど）の制作に興味を持つプロダクションから注目されています。  
私たちのアプローチは、少量の映像を使ってトレーニングすることができるので、個人的なストーリーテリング（それ自体が創造的で治療的な試みである）や、計算機や芸術的なリソースは少なくても、教室でのフィードバックや再トレーニングを即座に行うことができる教育の場でも使用することができます。

#### abuse(悪用)
視聴覚リターゲティングは、プロパガンダ目的の虚偽情報の拡散やポルノコンテンツの制作など、悪意を持って利用される可能性があることを認識することが重要です。  
これらの悪用に対処するためには、技術的な解決策だけでなく、名誉毀損、プライバシー、著作権、フェアユースの境界を明確にするために、社会科学者、政策立案者、倫理学者との議論が必要である。  
ここでは、この重要な議論を始めようとしています。まず、(Fried et al., 2019)に触発されて、我々の手法を用いたAVコンテンツ作成の推奨ポリシーを紹介する。  
私たちの設定では、リターゲティングには、音声信号を入力するソース個人と、ソースの言葉に合わせて視聴覚クリップを編集されるターゲット個人の2つのメディアが含まれます。  
悪用される可能性があるのは、ソースの盗用（例えば、他人の言葉を自分の言葉として表現すること）やターゲットの誤認識／著作権侵害などです。  
したがって、私たちは、常にソースコンテンツを引用し、常に対象となる個人から許可を得るというポリシーを提唱します。  
このポリシーに例外があるとすれば、教育、解説、パロディ（例：Putinでゼブラのテクスチャをリターゲティングする（Zhu et al.2017））などの一般的なフェアユース4に該当する可能性があります。  
いずれの場合も、リターゲットされたコンテンツは、パロディであることを明示するか、ウォーターマークを介して、編集されたものであることを認識する必要があります。  
重要なのは、このポリシーに違反する可能性があるということです。  
したがって、主要な課題は、そのような違反を特定し、後述するような違反によって引き起こされる害を軽減することです。

#### Audiovisual Forensics (鑑識)
ここでは、誤用とそれによって引き起こされる害を特定しようとする3つの戦略について説明します。  
これらの戦略はすべてを網羅しているわけではないことを強調しておきます。  
(a)フェイクコンテンツの特定  
(b)データの匿名化  
(c)技術の認知  

(a) AVコンテンツを編集するためのアプローチが成熟するにつれ、そのような「偽物」コンテンツを検出するための類似のアプローチが社会に求められている。  
現在のフォレンジック検出器は、分類タスクを通じてオリジナルと合成されたメディアを区別するように訓練された、データ駆動型のものが多い。  
このようなフォレンジックの本物と偽物の分類器は、画像（Maximovら、2020年、Rosslerら、2019年、Wangら、2020年）と音声¨5,6の両方に存在する。  
偽のトレーニング例」を生成するためのコードへのアクセスは、偽のコンテンツを識別するための学習に不可欠であるため、私たちはコードを自由に利用できるようにすることを約束します。  
付録Bでは、Exemplar Autoencoderの偽物を検出するオーディオの広範な分析を行っています。  

(b) 不正使用を軽減するためのもう一つの戦略は、プライベートなメディアデータへのアクセスを制御することです。  
顔の検出やぼかしによる画像の匿名化は、現代のデータ収集に欠かせない手法として広く普及しており、EUの一般データ保護規則（GDPR）でも義務付けられています。  
米国では、連邦政府の盗聴規制により、事前の同意なしに口頭でのコミュニケーションを録音することができないため、音声に関する制限はさらに厳しいものとなっています（Stevens & Doyle, 2011）。  
画像の匿名化のための最近のアプローチは、生成モデルを利用しており、各顔を一般的なIDにリターゲットすることで、劣化しないでデータを非識別化します（例えば、データセット内の全員をPersonAのように見せる）(Maximov et al., 2020)。  
我々のオーディオリターゲティングアプローチは、録音中の全員をPersonAのように聞こえるようにすることで、オーディオの非識別化に使用できる可能性がある。  

(c) 最後に、音声記録は現在、法的証拠やバイオメトリック音声認識など、社会的に重要な場面で使用されていることを指摘します（例：電話での音声を自動認識して銀行口座にアクセスする（Stevens & Doyle, 2011））。  
我々の結果は、このようなユースケースを再評価し、文体の音声合成の文脈で徹底的にテストする必要があることを示唆している。  
言い換えれば，音声からどのような情報を確実に推定できるかを理解することは，社会にとって非常に重要であり，我々のアプローチはこの問題を実証的に探求するために使用することができる。

#### training datasets
最後に、オーディオおよびビデオコンテンツ生成のための先行的なアプローチとは異なる、我々の技術的アプローチのユニークな特性を指摘します。  
我々の模範的なアプローチは、人口規模のトレーニングデータセットへの依存度を低減します。  
既存の大規模データセットで訓練された顔合成モデルは、英語を話す有名人が多いかもしれないが、肌色、性別、言語が訓練データセットに多く含まれるサブ集団では、より高い精度が得られる可能性がある(Menon et al., 2020)。  
模範解答ベースの学習では、対象となる模範的な個人に対してモデルが学習されるため、異なる特性を示す可能性があります。  
しかし、集団ではなく単一の個体で事前学習を行うことで、対象となる個体への学習の収束を早めることができることがわかっています。  
集団規模の学習データ（英語が多いかもしれない）への依存度が低いため、模範モデルは、そのようなデータセットにあまり含まれていない方言や言語をよりよく一般化できる可能性があります。  
要約ビデオでは、マンダリン語やヒンディー語のスピーチでトレーニングすることなく、スタイル化された多言語翻訳（オリバーをマンダリン語とヒンディー語で話すようにリターゲットする）の結果を紹介しています。  

### appendix B forensic study
前のセクションでは、私たちの研究のポジティブな結果とネガティブな結果の両方について説明しました。  
先行技術と比較して、新規の成果のほとんどは、追加のモダリティとしてオーディオを使用することから生じています。  
本章では、模範的なオートエンコーダーの偽物が、特にそのような偽物に対して学習された場合、フォレンジック分類器によって高い精度で検出できることを示す研究を行いました。  
我々の研究が、操作されたオーディオビジュアルコンテンツの検出に関する追加のフォレンジック研究のきっかけとなることを期待しています。

#### Speaker Agnostic Discriminator
まず、CelebAudioからの6つのアイデンティティについて、本物/偽物のオーディオ分類器をトレーニングします。  
モデル構造は(Serra et al., 2019)と同じです。  
トレーニングデータセット`には、(1)6つのアイデンティティのリアルスピーチ。John F Kennedy, Alexei Efros, Nelson Mandela, Oprah Winfrey, Bill Clinton, and Takeo Kanade. それぞれ200センテンスを収録しています。  
(2) 偽のスピーチ：(1)の各文を、これら6つのIDの異なる話者に変えて生成したもの。つまり、合計1200の文章が生成されていることになります。  
2つのシナリオで性能をテストします。(1)訓練セット内の話者。(1)訓練対象内の話者：John F Kennedy, Alexei Efros, Nelson Mandela, Oprah Winfrey, Bill Clinton, Takeo Kanade; (2)訓練対象外の話者：Barack Obama, Theresa May: Barack Obama, Theresa May.   
テストセットの各IDには，100個の本物の文と100個の偽物の文が含まれています。  
また，同じ話者であっても，テスト用のスピーチはトレーニング用のスピーチとは分離していることを確認している．  
表4によると，分類器はセット内の話者の偽物を非常によく検出し，サンプル外の話者についても妥当な基準を提供できていることがわかる．

#### Speaker-Specific Discriminator
特定の偽物を検出するために、学習セットを1つのIDに限定しています。同一人物の異なるスタイルを得るために、Barack Obamaの4つの異なるスピーチに対して、4つの模範的なオートエンコーダを学習します。  
特定の偽物を検出するために、1つのスタイルのオバマ氏のみを学習し、4つのスタイルすべてでテストを行う。  
学習セットには，本物か偽物かにかかわらず，600の文が含まれている．  
テストセットの各スタイルには，本物か偽物かに関わらず，150の文が含まれています．  
表4に示すように，我々の分類器は，設定されていないスタイルであっても，偽のスピーチに対して信頼性の高い予測を行うことができる．