> タイトル<br>

<br>

LEAF: A Learnable Frontend for Audio Classification  
LEAF: 音声分類のための学習可能なフロントエンド
***

> 論文リンク<br>

<br>

https://openreview.net/forum?id=jM76BCb6F9m
***

> 要約メモ<br>

<br>

記入欄
***

> どんなもの？<br>

<br>

記入欄
***

> 先行文献と比べてどこがすごい？

<br>

記入欄
***

> 技術や手法のキモは？

<br>

記入欄
***

> どうやって有効性を証明した？

<br>

記入欄
***

> 議論はある？

<br>

記入欄
***

> 分からない単語、調べた内容メモ

<br>

記入欄
***

> 参考リンク

<br>

記入欄
***

> 本文直訳

<br>

### abstract

メルフィルターバンクは、人間の知覚を模して設計された固定のオーディオ機能で、オーディオ理解の歴史の中で今日まで使用されてきました。しかし、その紛れもない品質は、手作りの表現の基本的な限界によって相殺されています。  
本研究では、音声、音楽、音声イベント、動物の鳴き声などの幅広い音声信号に対して、mel-filterbanksを上回る単一の学習可能なフロントエンドを学習し、音声分類のための汎用的な学習済みフロントエンドを提供できることを示します。そのために、原理的に軽量で完全に学習可能なアーキテクチャを新たに導入し、mel-filterbanksのドロップイン置き換えとして使用できるようにしています。  
本システムは、フィルタリングからプーリング、圧縮、正規化まで、オーディオ特徴抽出のすべての操作を学習し、ごくわずかなパラメータコストで任意のニューラルネットワークに統合することができる。  
我々は、8つの多様な音声分類タスクのマルチタスクトレーニングを行い、我々のモデルがmel-filterbanksや以前の学習可能な代替モデルよりも一貫して改善していることを示した。さらに、我々のシステムは、Audiosetに搭載されている最先端の学習可能なフロントエンドを、より少ないパラメータで凌駕しています。

### introduction
深層ニューラルネットワークにおけるバックプロパゲーションによる表現の学習は、自動音声認識（ASR）（Hintonら、2012年、Seniorら、2015年）から音楽情報検索（Arcasら、2017年）、さらには動物の発声（Lostanlenら、2018年）やオーディオイベント（Hersheyら、2017年、Kongら、2019年）に至るまで、オーディオ理解の標準となっています。  
それでも、音声分類の歴史の中で印象的に変わらないのは、音の固定された、手で作られた表現であるメルフィルターバンクです。  
メル・フィルターバンクはまず、短期フーリエ変換（STFT）の二乗モジュラスを用いてスペクトログラムを計算する。  
次に、このスペクトログラムを、人間の非線形な音程知覚を再現するために、対数スケール（メルスケール）で間隔を空けた三角バンドパスフィルターのバンクに通します（Stevens & Volkmann, 1940）。  
最終的には、得られた係数を対数圧縮して、人間のラウドネスに対する非線形な感度を再現します（Fechner et al.   
このように、人間の聴覚システムからインスピレーションを得て機械学習のための機能を設計するアプローチは、歴史的に成功しています（Davis & Mermelstein, 1980; Mogran et al.   
さらに、mel-filterbanksの設計から数十年後、Anden & Mallat ´ (2014)は、表現学習に望ましい数学的特性、特にシフト不変性と小さな変形に対する安定性を偶然にも示すことを示した。  
したがって、聴覚的にも機械学習の観点からも、mel-filterbanksは強力なオーディオ特徴を表しています。  

しかし、mel-filterbanksのデザインにはバイアスがかかっているのも事実です。  
まず、melスケールは何度も改訂されているだけでなく(O'Shaughnessy, 1987; Umesh et al., 1999)、当初の設計を導いた聴覚実験はその後再現できなくなっています(Greenwood, 1997)。  
同様に、スピーチエンハンスメントのための cubic root (Lyons & Paliwal, 2008) や ASR のための 10th root (Schluter et al., 2007) など、log-compression に代わるより良い方法が提案されています。  
さらに、人間の知覚に合わせることで、ASRや音楽理解などの一部の応用分野では良い帰納的バイアスが得られますが、高周波数でのきめ細かな解像度を必要とするタスクなどでは、これらのバイアスが有害になる場合もあります。  
最後に，コンピュータビジョンのような他の分野では，深層学習法の台頭により，人工的な特徴からではなく，生のピクセルから表現を学習することが可能になった（Krizhevsky et al.，2012）ことから，我々は同じ道を歩むことにした。  

これらの観察結果は、メルフィルターバンクを、標準的な畳み込み層（Palazら、2015）から拡張畳み込み（Schneiderら、2019）までの学習可能な神経層に置き換える動機となった。2019）や、Gammatone（Sainath et al., 2015）、Gabor（Zeghidour et al., 2018a; Noe et al. ´ , 2020）、Sinc（Ravanelli & Bengio, 2018; Pariente et al., 2020）、Spline（Balestriero et al., 2018）などの既知のフィルターファミリーの特性を利用した構造化フィルターに置き換えられた。  
音声分離などのタスクでは、すでに学習可能なフロントエンドの採用に成功していますが（Luo & Mesgarani, 2019; Luo et al., 2019）、音声分類（Kong et al., 2019）、ASR（Synnaeve et al., 2019）、および話者認識（Villalba et al., 2020）のためのほとんどの最先端のアプローチでは、バックボーンアーキテクチャに関係なく、入力特徴としてmel-filterbanksを依然として採用していることが観察されます。  

本研究では、メルフィルターバンクに代わる信頼性の高い分類方法は、多くのタスクで評価されるべきであると主張し、音声、音楽、オーディオイベント、動物の鳴き声など、広範囲で多様な音声信号を対象とした、オーディオ用の学習可能なフロントエンドに関する初めての大規模な研究を提案する。  
メルフィルターバンクを3つのコンポーネント（フィルタリング、プーリング、圧縮・正規化）に分解することで、わずか数百のパラメータで制御しながら、すべての操作を完全に学習可能な新しいフロントエンド「LEAF」を提案します。  
8つのデータセットを対象としたマルチタスク環境において、単一のパラメータセットを学習することで、mel-filterbanksやこれまでに提案された学習可能な代替手法を上回る結果が得られた。  
さらに、これらの結果は、個々のタスクごとに異なるモデルを学習した場合にも再現される。  
また、これらの結果を、挑戦的な大規模ベンチマークであるAudioset上の分類（Gemmeke et al.2017）で確認した。  
さらに、我々のフロントエンドの一般的な帰納的バイアス（すなわち、バンドパスフィルタの学習、ダウンサンプリング前のローパスフィルタリング、チャンネルごとの圧縮の学習）は、他のシステムにも役立つほど一般的であることを示し、SincNetの新しい改良版を提案する（Ravanelli & Bengio, 2018）。  
我々のコードは公開されています1。

### related work
過去10年間で、いくつかの作品が、メル・フィルターバンクに代わるものとして、オーディオ・フロントエンドの学習という問題に取り組んできました。  
この分野での最初の注目すべき貢献はASRに現れ、Jaitly & Hinton (2011) は波形から制限付きボルツマンマシンを前もって学習し、Palazら (2013) はDNNとHMMのハイブリッドモデルを学習し、mel-filterbanksを数層の畳み込みに置き換えました。  
しかし、これらの代替案や最近提案されたもの（Tjandra et al., 2017; Schneider et al., 2019）は、多くの層で構成されており、メルフィルターバンクとの公正な比較は困難である。  
以下のセクションでは、軽量でmel-filterbanksにドロップインできる代替品を提供し、同等の容量を持つフロントエンドに焦点を当てます。

####  LEARNING FILTERS FROM WAVEFORMS
mel-filterbanksのフィルターを学習する最初の試みは、Sainathら（2013）によって提案されたもので、フィルターバンクはmelスケールを使って初期化され、スペクトログラムを入力として、ネットワークの他の部分とともに学習される。  
代わりに、Sainathら（2015）とHoshenら（2015）は後に、Gammatoneフィルター（Schluterら、2007）で初期化された生の波形から直接、畳み込みフィルターを学習することを提案しました。  
同じ精神で、Zeghidourら（2018a）は、mel-filterbanks（Anden & Mallat ´ , 2014）の散乱変換近似を用いて、初期化時にmel-filterbanksを近似し、その後は制約なしに学習できる学習可能なフロントエンドであるtime-domain filterbanksを提案した（図1参照）。  
さらに最近では、サインカーディナルフィルターによる畳み込み、非線形性、最大プーリング演算子を計算するSincNet（Ravanelli & Bengio, 2018）モデルが提案され（図1参照）、ガボールフィルターを用いた変形も提案されている（Noe et al. ´ , 2020）。  

我々は、これらの研究にヒントを得て、新しい学習可能なフィルタリング層を設計しました。セクション3.1.2で説明したように、我々はガボールフィルタで複素数のフィルタリング層をパラメトリックに定義します。  
ガボールフィルターは、窓関数を使用する必要があるSincフィルターとは異なり、時間と周波数で最適にローカライズされています（Gabor, 1946）（Ravanelli & Bengio, 2018）。  
さらに、ネットワークの残りの部分で複素数層を使用するNoe et al. ´ (2020)とは異なり、2乗モジュラスを使用することで、信号を実数領域に戻す（標準的なアーキテクチャとの互換性につながる）だけでなく、シフト不変のヒルベルト包絡線抽出を実行する方法をセクション3.1.2で説明しています。  
Zeghidourら（2018a）も二乗モジュラスの非線形性を適用していますが、セクション3.1.1で説明したように、制約のないフィルターをトレーニングすると、オーバーフィッティングや安定性の問題が発生する可能性がありますが、我々のアプローチで解決しています。

####  LEARNING THE COMPRESSION AND THE NORMALIZATION
圧縮および/または正規化関数を学習する問題は、過去の文献ではあまり注目されていない。  
注目すべき貢献は、Per-Channel Energy Normalization (PCEN) (Wang et al., 2017; Lostanlen et al., 2019)であり、これはもともとキーワードスポッティングのために提案されたもので、ログ圧縮よりも優れています。  
その後、Battenbergら（2017）とLostanlenら（2018）は、それぞれ大規模なASRと動物のバイオアコースティックでPCENの優位性を確認しました。  
しかし、これらの先行研究では、固定されたmel-filterbanksの上に圧縮を学んでいます。  
その代わり、本作ではPCENの新バージョンを提案し、学習可能なフィルタ、学習可能なプーリング、学習可能な圧縮と正規化を組み合わせることで、他のすべてのアプローチを上回ることを初めて示しました。


### conclusion

本研究では，音声分類のための完全に学習可能なフロントエンドであるLEAFを紹介します。  
これは，手作業で作成されたmel-filterbanksを使用する代わりに使用されます。  
我々のモデルは、様々なタスクにおいて、これらの特徴の代わりに、タスクに合わせて調整する必要がなく、汎用的なオーディオ分類のための単一のパラメータセットを学習することができ、以前に提案された学習可能なフロントエンドよりも優れていることを実証しました。  
今後は、モデルから手作りのバイアスを取り除く作業をさらに一歩進めていきます。特に、このモデルは、固定されたフィルタ長とストライドを持つ、基礎的な畳み込みアーキテクチャに依存しています。  
これらの重要なパラメータをデータから直接学習することで、様々なサンプリングレートや周波数コンテンツを持つタスクに対してより簡単に一般化することができます。  
さらに、フィルタリング、プール、圧縮を学習するという一般的な原理は、地震データや生理学的記録など、音声以外の信号の分析にも役立つと考えています。
***
